from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import random

app = Flask(__name__)
CORS(app)

# Load model v√† d·ªØ li·ªáu
model_path = "/Users/trananhtuan/Documents/datsan247/Badminton_Manager/AI/badminton_qa_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForQuestionAnswering.from_pretrained(model_path)
embedding_model = SentenceTransformer('distilbert-base-nli-mean-tokens')

df = pd.read_csv("/Users/trananhtuan/Documents/datsan247/Badminton_Manager/AI/data/Question.csv")

topic_dict = {
    "booking": ["book", "reservation", "schedule", "available", "court", "time", "slot", "booking", "reschedule", "tournament", "organize", "session", "reserve", "advance", "statistics", "history", "past"],
    "account": ["personal", "information", "login", "password", "register", "account", "profile", "signin", "signup", "forgot", "email", "facebook", "instagram", "twitter", "tiktok", "zalo", "microsoft", "phone", "reset", "create", "sign up", "format"],
    "equipment": ["racket", "rent", "shuttlecock", "equipment", "purchase", "buy", "drinks", "water"],
    "facilities": ["changing room", "locker", "parking", "facility", "toilet", "shower", "indoor", "outdoor", "location", "address"],
    "payment": ["pay", "payment", "fee", "cost", "price", "refund", "cancel", "money","charged", "free", "rate", "hourly", "vnd"],
    "contact": ["contact", "staff", "help", "support", "question", "assistance", "email", "call", "hotline", "phone", "message", "reply", "respond", "inquiry", "email", "hotline"],
    "website": ["news", "updates", "promotions", "discounts", "services", "policy", "terms", "guidelines", "introduction", "homepage", "section", "button"],
    "misc": []  # M·∫∑c ƒë·ªãnh cho c√¢u h·ªèi kh√¥ng thu·ªôc ch·ªß ƒë·ªÅ n√†o
}

# X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ cho c√¢u h·ªèi
def identify_topic(question):
    question = question.lower()
    
    # Ki·ªÉm tra t·ª´ng ch·ªß ƒë·ªÅ
    for topic, keywords in topic_dict.items():
        for keyword in keywords:
            if keyword in question:
                return topic
    
    return "misc"  # Ch·ªß ƒë·ªÅ m·∫∑c ƒë·ªãnh

# T·∫°o context theo ch·ªß ƒë·ªÅ
def create_topic_contexts(df):
    topic_contexts = {}
    
    # Kh·ªüi t·∫°o context cho m·ªói ch·ªß ƒë·ªÅ
    for topic in topic_dict.keys():
        topic_contexts[topic] = ""
    
    # Ph√¢n lo·∫°i c√¢u h·ªèi v√†o c√°c ch·ªß ƒë·ªÅ
    for _, row in df.iterrows():
        question = row['Question']
        answer = row['Answer']
        
        # X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ
        topic = identify_topic(question)
        
        # Th√™m v√†o context c·ªßa ch·ªß ƒë·ªÅ t∆∞∆°ng ·ª©ng
        topic_contexts[topic] += f"Question: {question}\nAnswer: {answer}\n\n"
    
    return topic_contexts

# T·∫°o embeddings cho t·∫•t c·∫£ c√¢u h·ªèi
def create_question_embeddings(df):
    questions = df['Question'].tolist()
    embeddings = embedding_model.encode(questions)
    return embeddings

# T√¨m c√¢u h·ªèi t∆∞∆°ng t·ª± nh·∫•t
def find_similar_questions(question, df, embeddings, top_k=3):
    # T·∫°o embedding cho c√¢u h·ªèi
    question_embedding = embedding_model.encode([question])[0]
    
    # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
    similarities = cosine_similarity([question_embedding], embeddings)[0]
    
    # L·∫•y top_k c√¢u h·ªèi c√≥ ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    
    # T·∫°o context t·ª´ top_k c√¢u h·ªèi
    context = ""
    for idx in top_indices:
        q = df.iloc[idx]['Question']
        a = df.iloc[idx]['Answer']
        context += f"Question: {q}\nAnswer: {a}\n\n"
    
    return context, similarities[top_indices[0]]

# Kh·ªüi t·∫°o contexts v√† embeddings
topic_contexts = create_topic_contexts(df)
embeddings = create_question_embeddings(df)

# S·ª≠ d·ª•ng
def smart_qa_system(question, df, model, tokenizer):
    # X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ
    topic = identify_topic(question)

    if topic == "misc":
        default_responses = [
            "I don't understand your question.", 
            "Please ask again."
        ]
        random_response = random.choice(default_responses)
        return random_response, 1.0, "default_response"

    similar_questions_df = df[df['Question'].apply(lambda q: identify_topic(q) == topic)]
    if len(similar_questions_df) > 0:
        similar_embeddings = create_question_embeddings(similar_questions_df)
        context, similarity = find_similar_questions(question, similar_questions_df, similar_embeddings)
        
        # N·∫øu ƒë·ªô t∆∞∆°ng ƒë·ªìng cao, tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp
        if similarity > 0.85:
            for idx in np.argsort(cosine_similarity([embedding_model.encode([question])[0]], similar_embeddings)[0])[-1:]:
                return similar_questions_df.iloc[idx]['Answer'], similarity, "direct_match"
            
    context = topic_contexts[topic]
    
    # S·ª≠ d·ª•ng pipeline question-answering
    nlp = pipeline("question-answering", model=model, tokenizer=tokenizer)
    result = nlp(question=question, context=context)
    
    return result['answer'], result['score'], "model_answer"

@app.route('/api/chat', methods=['POST'])
def chat():
    print("üì• ƒê√£ nh·∫≠n request t·ªõi /api/chat")
    
    data = request.json
    user_message = data.get('message', '')

    if not user_message:
        return jsonify({"answer": "B·∫°n ch∆∞a nh·∫≠p c√¢u h·ªèi.", "score": 0, "method": "error"})
    
    if not user_message:
        return jsonify({'error': 'No message provided'}), 400
    
    answer, score, method = smart_qa_system(user_message, df, model, tokenizer)
    
    return jsonify({
        'answer': answer,
        'score': float(score),
        'method': method
    })

if __name__ == "__main__":
    app.run(debug=True, port=5001)